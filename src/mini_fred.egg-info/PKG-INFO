Metadata-Version: 2.4
Name: mini-fred
Version: 0.1.0
Summary: Minimal, reproducible Mini-FRED warehouse scaffolding
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: duckdb>=0.10
Requires-Dist: pandas>=2.2
Requires-Dist: pyyaml>=6.0
Requires-Dist: requests>=2.32
Requires-Dist: python-dotenv>=1.0
Requires-Dist: scikit-learn>=1.4
Provides-Extra: dev
Requires-Dist: pytest>=8.0; extra == "dev"

## Mini-FRED Warehouse

Purpose is to create a deterministic, lightweight subset of key macroeconomic series that can be stored locally in DuckDB and reused for MVES verifiers and promptfoo experiments without requiring a network connection after the initial ingest.

### Quickstart
1. `cd mini-fred`
2. Create a virtual environment (example): `python3 -m venv .venv && source .venv/bin/activate`
3. Install dependencies (DuckDB, pandas, scikit-learn, etc.): `pip install -e .`
4. Provide your FRED key (needed only for online ingest) by creating a `.env` file that contains `FRED_API_KEY=YOUR_KEY` or exporting the variable manually.
5. Run the ingest command (see below) to populate DuckDB + snapshots.
6. Execute QC checks to validate the snapshot.
7. Generate Markdown series cards.
8. Ask a question using the deterministic answer CLI.

### Ingest & QC
```
# .env is read automatically; this manual export is optional
export FRED_API_KEY=YOUR_KEY
python scripts/ingest_fred.py --refresh --export-snapshots
python scripts/qc_checks.py
python scripts/build_series_cards.py --last-n 12
python scripts/answer.py "What was the unemployment rate in April 2020?"
```
The ingest script downloads metadata + observations for CPIAUCSL, UNRATE, FEDFUNDS, PCEPI, and GDPC1 from 2000-01-01 through 2025-12-31, writes them into `data/warehouse.duckdb`, caches raw JSON in `data/raw/`, and optionally exports CSV snapshots under `data/snapshots/`. After a snapshot exists, downstream demos can run offline without reusing the API key because all inputs are already committed.

### Series cards & answerer
- `python scripts/build_series_cards.py --last-n 12` writes `corpus/series_cards/series_<SERIES>.md` (the context plane for RAG-style explanations).
- `python scripts/answer.py "What was the unemployment rate in April 2020?"` loads the DuckDB truth store, uses TF-IDF retrieval over `corpus/series_cards` to ground/infer series IDs, computes the numeric answer, and emits JSON (value, explanation text, deterministic citations, retrieved doc scores).

### MVES: running evaluations
- Specs, verifiers, and goldens live in `mves/` + `eval/golden.jsonl`.
- Regenerate the data-derived golden set with `python scripts/generate_golden.py --out eval/golden.jsonl` (see `--help` for sampling knobs). Ambiguity tests live in `eval/refusal.jsonl`.
- Run the full gate with `python scripts/mves_run.py`.
- Results land in `reports/mves_report.json|md`. The runner exits non-zero if any critical verifier fails or pass rate drops below 90%.

### Next milestones
- Commit reproducible data snapshots for offline truth checks.
- Wire promptfoo/MVES verifiers to cite the committed series cards.

### Environment variables
- `FRED_API_KEY`: store it in `.env` (preferred) or export it before running ingest. Once snapshots are checked in, the warehouse can be queried offline without this key.
